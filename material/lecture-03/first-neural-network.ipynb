{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your First Neural Network\n",
    "\n",
    "Let's create a neural network that can label fashion items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split off some validation data\n",
    "\n",
    "To measure our Neural Networks performance we will need some validation data. The `train_test_split` helper from scikit-learn does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                  test_size=10000,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One more thing\n",
    "\n",
    "We need to convert the labels from integers (0, 1, 2, 3, ...) to  a one-hot encoding. The one-hot encoding for a problem with ten classes is a ten dimensional vector for each sample. For a sample in class 4 every entry is zero except for the fourth one. Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "y_train_ = utils.to_categorical(y_train, num_classes)\n",
    "y_val = utils.to_categorical(y_val, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 0, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make y_train the same as the others\n",
    "y_train = utils.to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Network Building Blocks\n",
    "\n",
    "A neural network is a stack of functions that are applied to the input data in order. Let's import some building blocks and create our first neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define the input shape (i.e., how many input features) **without** the batch size\n",
    "x = Input(shape=(28, 28, ))\n",
    "\n",
    "# turn a 28x28 matrix into a 784-d vector, this removes all information\n",
    "# about the spatial relation between pixels. Using convolutions will\n",
    "# allow us to take advantage of that information (see later)\n",
    "h = Flatten()(x)\n",
    "\n",
    "# all Keras Ops look like z = f(z) (like functional programming)\n",
    "h = Dense(100)(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(100)(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "# we want to predict one of ten classes\n",
    "h = Dense(10)(h)\n",
    "y = Activation('softmax')(h)\n",
    "\n",
    "# Package it all up in a Model\n",
    "net = Model(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the model\n",
    "\n",
    "We can plot the model as a graph. This requires `pydot` which is a bit tricky to setup (even though everyone uses it). We will see an alternative way of looking at the model in a moment. If installing `pyplot` doesn't just work don't spend time trying to debug it. You can sink days into this ... :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/adv-comp-18/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7e13d7910a02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'basic-net.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/adv-comp-18/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/adv-comp-18/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/adv-comp-18/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     32\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "plot_model(net, to_file='basic-net.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=\"basic-net.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Time to train the model using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# a way to use a different optimiser\n",
    "sgd = SGD(lr=0.5)\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "This is an alternative way of visualising the network and lots of other statistics about the training process.\n",
    "\n",
    "https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/thead/anaconda/envs/adv-comp-18/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [TensorBoard('fashion-tb',\n",
    "                         histogram_freq=1,\n",
    "                         write_grads=True,\n",
    "                         write_graph=True,\n",
    "                         batch_size=batch_size,\n",
    "                         write_images=True,)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.5274 - acc: 0.8171 - val_loss: 0.4438 - val_acc: 0.8426\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 0.3815 - acc: 0.8625 - val_loss: 0.3660 - val_acc: 0.8676\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.3453 - acc: 0.8736 - val_loss: 0.3552 - val_acc: 0.8652\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.3192 - acc: 0.8836 - val_loss: 0.3470 - val_acc: 0.8757\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.3002 - acc: 0.8886 - val_loss: 0.3463 - val_acc: 0.8718\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.2867 - acc: 0.8941 - val_loss: 0.3240 - val_acc: 0.8787\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.2714 - acc: 0.8990 - val_loss: 0.3328 - val_acc: 0.8768\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.2611 - acc: 0.9032 - val_loss: 0.3329 - val_acc: 0.8812\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.2550 - acc: 0.9040 - val_loss: 0.3286 - val_acc: 0.8822\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.2393 - acc: 0.9096 - val_loss: 0.3285 - val_acc: 0.8853\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.2329 - acc: 0.9133 - val_loss: 0.3432 - val_acc: 0.8838\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.2254 - acc: 0.9151 - val_loss: 0.3458 - val_acc: 0.8828\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.2171 - acc: 0.9190 - val_loss: 0.3299 - val_acc: 0.8828\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.2105 - acc: 0.9202 - val_loss: 0.3353 - val_acc: 0.8849\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.2049 - acc: 0.9228 - val_loss: 0.3331 - val_acc: 0.8866\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.1994 - acc: 0.9244 - val_loss: 0.3423 - val_acc: 0.8837\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.1926 - acc: 0.9266 - val_loss: 0.3286 - val_acc: 0.8921\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.1857 - acc: 0.9298 - val_loss: 0.3723 - val_acc: 0.8823\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.1832 - acc: 0.9305 - val_loss: 0.3314 - val_acc: 0.8872\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.1762 - acc: 0.9336 - val_loss: 0.3431 - val_acc: 0.8907\n"
     ]
    }
   ],
   "source": [
    "history = net.fit(X_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=20,\n",
    "                  verbose=1,\n",
    "                  callbacks=callbacks,\n",
    "                  validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our model we can make predictions and hope that they are better. The highest probability should be at the index that corresponds to the correct class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.07623606e-11, 1.11054796e-17, 1.73294007e-16, 4.91198726e-15,\n",
       "        2.93793337e-13, 2.35333664e-09, 5.85441539e-16, 2.69761852e-10,\n",
       "        1.00000000e+00, 2.47993442e-18],\n",
       "       [9.18707485e-07, 7.70173178e-16, 4.69731025e-12, 9.79379745e-14,\n",
       "        2.81663159e-09, 3.04540003e-13, 2.42390530e-09, 1.63089065e-13,\n",
       "        9.99999046e-01, 2.51452873e-12],\n",
       "       [4.61602839e-10, 3.76231121e-12, 5.89687668e-14, 2.73960491e-14,\n",
       "        2.54595000e-12, 3.72057802e-05, 1.33031281e-12, 9.99962568e-01,\n",
       "        3.16660088e-12, 2.23594867e-07],\n",
       "       [1.61864315e-04, 8.83634073e-08, 1.06310919e-01, 1.72881503e-03,\n",
       "        7.82286763e-01, 5.97001293e-09, 1.09197192e-01, 2.30765545e-06,\n",
       "        3.11947952e-04, 1.01157084e-07],\n",
       "       [1.25463515e-15, 4.54630355e-19, 7.61620733e-20, 1.93747851e-17,\n",
       "        3.19263531e-15, 8.65770838e-17, 2.71701286e-18, 1.31319487e-11,\n",
       "        1.00000000e+00, 1.77015624e-15]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict(X_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x126eb1f98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqTyuwlXHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126c55048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.ylim([0, None])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
